API Reference
Lemur
Ask questions using LeMUR

POST
https://api.assemblyai.com/lemur/v3/generate/question-answer
POST
/lemur/v3/generate/question-answer

curl -X POST https://api.assemblyai.com/lemur/v3/generate/question-answer \
     -H "Authorization: <Authorization>" \
     -H "Content-Type: application/json" \
     -d '{
  "final_model": "anthropic/claude-3-7-sonnet-20250219",
  "questions": [
    {
      "question": "Where are there wildfires?",
      "answer_format": "List of countries in ISO 3166-1 alpha-2 format",
      "answer_options": [
        "US",
        "CA"
      ]
    },
    {
      "question": "Is global warming affecting wildfires?",
      "answer_options": [
        "yes",
        "no"
      ]
    }
  ],
  "context": "This is an interview about wildfires.",
  "max_output_size": 3000,
  "temperature": 0,
  "transcript_ids": [
    "64nygnr62k-405c-4ae8-8a6b-d90b40ff3cce"
  ]
}'
Try it
200
lemurQuestionAnswerExample

{
  "request_id": "5e1b27c2-691f-4414-8bc5-f14678442f9e",
  "response": [
    {
      "question": "Where are there wildfires?",
      "answer": "CA, US"
    },
    {
      "question": "Is global warming affecting wildfires?",
      "answer": "yes"
    }
  ],
  "usage": {
    "input_tokens": 27,
    "output_tokens": 3
  }
}
LeMUR is currently not available on the EU endpoint.
Question & Answer allows you to ask free-form questions about a single transcript or a group of transcripts. The questions can be any whose answers you find useful, such as judging whether a caller is likely to become a customer or whether all items on a meetingâ€™s agenda were covered.

Headers
Authorization
string
Required
Request
Params to ask questions about the transcripts

final_model
enum
Required
The model that is used for the final prompt after compression is performed.


Show 6 enum values
questions
list of objects
Required
A list of questions to ask


Show 4 properties
context
string or map from strings to any
Optional
Context to provide the model. This can be a string or a free-form JSON value.


Show 2 variants
input_text
string
Optional
Custom formatted transcript data. Maximum size is the context limit of the selected model, which defaults to 100000. Use either transcript_ids or input_text as input into LeMUR.

max_output_size
integer
Optional
Defaults to 2000
Max output size in tokens, up to 4000

temperature
double
Optional
The temperature to use for the model. Higher values result in answers that are more creative, lower values are more conservative. Can be any value between 0.0 and 1.0 inclusive.

transcript_ids
list of strings
Optional
A list of completed transcripts with text. Up to a maximum of 100 files or 100 hours, whichever is lower. Use either transcript_ids or input_text as input into LeMUR.

Response
LeMUR question & answer response

request_id
string
format: "uuid"
The ID of the LeMUR request

response
list of objects
The answers generated by LeMUR and their questions


Show 2 properties
usage
object
The usage numbers for the LeMUR request


Show 2 properties
Errors

400
Bad Request Error

401
Unauthorized Error

404
Not Found Error

429
Too Many Requests Error

500
Internal Server Error

503
Service Unavailable Error

504
Gateway Timeout Error
Was this page helpful?
Yes
No
Previous
Retrieve LeMUR response

Next
Built with