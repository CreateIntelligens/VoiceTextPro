API Reference
Lemur
Summarize a transcript using LeMUR

POST
https://api.assemblyai.com/lemur/v3/generate/summary
POST
/lemur/v3/generate/summary

curl -X POST https://api.assemblyai.com/lemur/v3/generate/summary \
     -H "Authorization: <Authorization>" \
     -H "Content-Type: application/json" \
     -d '{
  "final_model": "anthropic/claude-3-7-sonnet-20250219",
  "context": "This is an interview about wildfires.",
  "max_output_size": 3000,
  "temperature": 0,
  "transcript_ids": [
    "47b95ba5-8889-44d8-bc80-5de38306e582"
  ]
}'
Try it
200
lemurSummaryExample

{
  "request_id": "5e1b27c2-691f-4414-8bc5-f14678442f9e",
  "response": "- Wildfires in Canada are sending smoke and air pollution across parts of the US, triggering air quality alerts from Maine to Minnesota. Concentrations of particulate matter have exceeded safety levels.\n\n- Weather systems are channeling the smoke through Pennsylvania into the Mid-Atlantic and Northeast regions. New York City has canceled outdoor activities to keep children and vulnerable groups indoors.\n\n- Very small particulate matter can enter the lungs and impact respiratory, cardiovascular and neurological health. Young children, the elderly and those with preexisting conditions are most at risk.\n\n- The conditions causing the poor air quality could get worse or shift to different areas in coming days depending on weather patterns. More wildfires may also contribute to higher concentrations.\n\n- Climate change is leading to longer and more severe fire seasons. Events of smoke traveling long distances and affecting air quality over wide areas will likely become more common in the future.\"\n",
  "usage": {
    "input_tokens": 27,
    "output_tokens": 3
  }
}
LeMUR is currently not available on the EU endpoint.
Custom Summary allows you to distill a piece of audio into a few impactful sentences. You can give the model context to obtain more targeted results while outputting the results in a variety of formats described in human language.

Headers
Authorization
string
Required
Request
Params to generate the summary

final_model
enum
Required
The model that is used for the final prompt after compression is performed.


Show 6 enum values
answer_format
string
Optional
How you want the summary to be returned. This can be any text. Examples: “TLDR”, “bullet points”

context
string or map from strings to any
Optional
Context to provide the model. This can be a string or a free-form JSON value.


Show 2 variants
input_text
string
Optional
Custom formatted transcript data. Maximum size is the context limit of the selected model, which defaults to 100000. Use either transcript_ids or input_text as input into LeMUR.

max_output_size
integer
Optional
Defaults to 2000
Max output size in tokens, up to 4000

temperature
double
Optional
The temperature to use for the model. Higher values result in answers that are more creative, lower values are more conservative. Can be any value between 0.0 and 1.0 inclusive.

transcript_ids
list of strings
Optional
A list of completed transcripts with text. Up to a maximum of 100 files or 100 hours, whichever is lower. Use either transcript_ids or input_text as input into LeMUR.

Response
LeMUR summary response

request_id
string
format: "uuid"
The ID of the LeMUR request

response
string
The response generated by LeMUR.

usage
object
The usage numbers for the LeMUR request


Show 2 properties
Errors

400
Bad Request Error

401
Unauthorized Error

404
Not Found Error

429
Too Many Requests Error

500
Internal Server Error

503
Service Unavailable Error

504
Gateway Timeout Error
Was this page helpful?
Yes
No
Previous
Ask questions using LeMUR

Next
Built with